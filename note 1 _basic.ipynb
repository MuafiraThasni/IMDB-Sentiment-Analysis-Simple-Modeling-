{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8a17cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f39785b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('IMDB_Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e92e3668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "(50000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea40c4",
   "metadata": {},
   "source": [
    "So there are no missing entries in the data. But this data set contains 50 k movie reviews. Since this is alarge data set, for effective performance, a subset of 10,000 entries can be considered. Among these, 7000 are of positive review and 3000 are of negative. This ratio is just for learning how to deal with imbalanced data. Because I have to face dirty and imbalanced data while dealing with real time projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a675ba5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_positive = df[df['sentiment']=='positive'][:7000]\n",
    "df_negative = df[df['sentiment']=='negative'][:3000]\n",
    "df_new = pd.concat([df_positive,df_negative])\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8e1addc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14162</th>\n",
       "      <td>Radio is a true story about a man who did what...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "14162  Radio is a true story about a man who did what...  positive\n",
       "3      Basically there's a family where a little boy ...  negative"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[6999:7001]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f50d6",
   "metadata": {},
   "source": [
    "Now the data frame is ready. Next step is splitting it up as training set and test set. Before that, it can be noted that these data set is imbalanced, as decided earlier. So how to deal with this imbalanced data...? There are two methods, one is undersampling the positive to the level of negative reviews. second is it's opposit, that is oversampling. Here for an instance, oversampling is selected. Since in the reference material, they selected undersampling, so I decided to try oversampling. Actually I should find later the method to be chosen to find the best way here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3415543a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9786</th>\n",
       "      <td>I first saw this film in the late 60's, and tr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>OK, so I don't watch too many horror movies - ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11843</th>\n",
       "      <td>Ray is one of those movies that makes you paus...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9387</th>\n",
       "      <td>Disgused as an Asian Horror, \"A Tale Of Two Si...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>Okay, I know I shouldn't like this movie but I...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14015</th>\n",
       "      <td>This is one of the best Fred Astaire-Ginger Ro...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8569</th>\n",
       "      <td>This is actually a groovy-neat little flick, m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>I cannot believe it has been 25 yrs since I fi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>I put this second version of \"The Man Who Knew...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8424</th>\n",
       "      <td>An introspective look at the relationship betw...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "9786   I first saw this film in the late 60's, and tr...  positive\n",
       "6757   OK, so I don't watch too many horror movies - ...  positive\n",
       "11843  Ray is one of those movies that makes you paus...  positive\n",
       "9387   Disgused as an Asian Horror, \"A Tale Of Two Si...  positive\n",
       "3661   Okay, I know I shouldn't like this movie but I...  positive\n",
       "...                                                  ...       ...\n",
       "14015  This is one of the best Fred Astaire-Ginger Ro...  positive\n",
       "8569   This is actually a groovy-neat little flick, m...  positive\n",
       "2593   I cannot believe it has been 25 yrs since I fi...  positive\n",
       "7488   I put this second version of \"The Man Who Knew...  positive\n",
       "8424   An introspective look at the relationship betw...  positive\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_len = 3000\n",
    "pos_len = 7000\n",
    "#df_neg = df_negative.sample(n=pos_len)\n",
    "df_pos = df_positive.sample(n=neg_len)\n",
    "df_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f9f4cc",
   "metadata": {},
   "source": [
    "I failed to do oversampling, so i have done under sampling. There are some modules and methods for these. But now I am going with this. Later, this topic should be covered in detail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f755193c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9786</th>\n",
       "      <td>I first saw this film in the late 60's, and tr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>OK, so I don't watch too many horror movies - ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11843</th>\n",
       "      <td>Ray is one of those movies that makes you paus...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9387</th>\n",
       "      <td>Disgused as an Asian Horror, \"A Tale Of Two Si...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>Okay, I know I shouldn't like this movie but I...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>Something somewhere must have terribly gone wr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5942</th>\n",
       "      <td>This was the next to last film appearance by J...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5946</th>\n",
       "      <td>I give this movie a 4 cause I'm a die hard fan...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>Are we serious??? I mean wow ... just, wow. I ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>I have no respect for IMDb ratings anymore. I ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "9786   I first saw this film in the late 60's, and tr...  positive\n",
       "6757   OK, so I don't watch too many horror movies - ...  positive\n",
       "11843  Ray is one of those movies that makes you paus...  positive\n",
       "9387   Disgused as an Asian Horror, \"A Tale Of Two Si...  positive\n",
       "3661   Okay, I know I shouldn't like this movie but I...  positive\n",
       "...                                                  ...       ...\n",
       "5939   Something somewhere must have terribly gone wr...  negative\n",
       "5942   This was the next to last film appearance by J...  negative\n",
       "5946   I give this movie a 4 cause I'm a die hard fan...  negative\n",
       "5947   Are we serious??? I mean wow ... just, wow. I ...  negative\n",
       "5948   I have no respect for IMDb ratings anymore. I ...  negative\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bal = pd.concat([df_pos,df_negative])\n",
    "df_bal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4a444",
   "metadata": {},
   "source": [
    "Splitting data into training set and test set. Here 67 percentage of data is chosen as training set and 33 % is chosen as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e0b51e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9536     After the initial shock of realizing the guts ...\n",
       "2184     This has to be the funniest stand up comedy I ...\n",
       "6185     This movie is sort of a Carrie meets Heavy Met...\n",
       "7316     Will and Ted's Bodacious journey is an existen...\n",
       "7152     Aside from the great movie METROPOLIS, this is...\n",
       "                               ...                        \n",
       "4477     I didn't like watching DS9 compared to other S...\n",
       "5655     There wasn't much thought put into the story l...\n",
       "5160     Kidman and Law lack the chemistry to make this...\n",
       "13450    Let me get the bad out of the way first, James...\n",
       "495      \"American Nightmare\" is officially tied, in my...\n",
       "Name: review, Length: 1980, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "R_train,R_test,S_train,S_test = train_test_split(df_bal['review'],df_bal['sentiment'],test_size=.33)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab65cb94",
   "metadata": {},
   "source": [
    "Our data is a raw test document. to do analysis, this should be convereted into numerical vectors. There are three methods, Bag of words, wor2vec, one hot encoding. Here BOW is used. Among the two methods in BOW, TF-IDF(Term Frequency-Inverse Documant Frequency) is the best method for this application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b2746b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75cd07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = text.TfidfVectorizer(stop_words = 'english')\n",
    "train_R_vector = tfidf.fit_transform(R_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba1c8e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00001</th>\n",
       "      <th>007</th>\n",
       "      <th>00am</th>\n",
       "      <th>00s</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>...</th>\n",
       "      <th>zzzzip</th>\n",
       "      <th>álvaro</th>\n",
       "      <th>ángel</th>\n",
       "      <th>æon</th>\n",
       "      <th>élan</th>\n",
       "      <th>ís</th>\n",
       "      <th>ísnt</th>\n",
       "      <th>île</th>\n",
       "      <th>óli</th>\n",
       "      <th>önsjön</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11058</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6979</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.097448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4020 rows × 35118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             00  000  00001  007      00am  00s   01   02   04   05  ...  \\\n",
       "3145   0.000000  0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "11058  0.000000  0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "5523   0.000000  0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "5275   0.000000  0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4389   0.000000  0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "...         ...  ...    ...  ...       ...  ...  ...  ...  ...  ...  ...   \n",
       "4367   0.000000  0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "5935   0.000000  0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "684    0.000000  0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "6979   0.000000  0.0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "145    0.097448  0.0    0.0  0.0  0.124534  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "       zzzzip  álvaro  ángel  æon  élan   ís  ísnt  île  óli  önsjön  \n",
       "3145      0.0     0.0    0.0  0.0   0.0  0.0   0.0  0.0  0.0     0.0  \n",
       "11058     0.0     0.0    0.0  0.0   0.0  0.0   0.0  0.0  0.0     0.0  \n",
       "5523      0.0     0.0    0.0  0.0   0.0  0.0   0.0  0.0  0.0     0.0  \n",
       "5275      0.0     0.0    0.0  0.0   0.0  0.0   0.0  0.0  0.0     0.0  \n",
       "4389      0.0     0.0    0.0  0.0   0.0  0.0   0.0  0.0  0.0     0.0  \n",
       "...       ...     ...    ...  ...   ...  ...   ...  ...  ...     ...  \n",
       "4367      0.0     0.0    0.0  0.0   0.0  0.0   0.0  0.0  0.0     0.0  \n",
       "5935      0.0     0.0    0.0  0.0   0.0  0.0   0.0  0.0  0.0     0.0  \n",
       "684       0.0     0.0    0.0  0.0   0.0  0.0   0.0  0.0  0.0     0.0  \n",
       "6979      0.0     0.0    0.0  0.0   0.0  0.0   0.0  0.0  0.0     0.0  \n",
       "145       0.0     0.0    0.0  0.0   0.0  0.0   0.0  0.0  0.0     0.0  \n",
       "\n",
       "[4020 rows x 35118 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.sparse.from_spmatrix(train_R_vector,\n",
    "                                  index=R_train.index,\n",
    "                                  columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78961b09",
   "metadata": {},
   "source": [
    "Similarly, test set of review also should be transformed into numerical vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a0b4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_R_vector = tfidf.transform(R_test)# since tfidf is already fit, only transformation is needed for test data, no need of fit again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92521c9c",
   "metadata": {},
   "source": [
    "Now the data is all set for modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "071456d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = LogisticRegression()\n",
    "#model = RandomForestClassifier()\n",
    "#model = SVC()\n",
    "#model = DecisionTreeClassifier()\n",
    "GaussianNB = GaussianNB()\n",
    "\n",
    "model.fit(train_R_vector,S_train)\n",
    "S_pred = model.predict(test_R_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37715ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as acy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "02f5014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC= 0.843939393939394\n",
      "LR= 0.8712121212121212\n",
      "SVC= 0.8696969696969697\n",
      "DTC= 0.702020202020202\n",
      "GNB= 0.705050505050505\n"
     ]
    }
   ],
   "source": [
    "#accuracy_RFC = acy(S_test,S_pred)\n",
    "#accuracy_LR = acy(S_test,S_pred)\n",
    "#accuracy_SVC = acy(S_test,S_pred)\n",
    "#accuracy_DTC = acy(S_test,S_pred)\n",
    "accuracy_GNB = acy(S_test,S_pred)\n",
    "print(\"RFC=\",accuracy_RFC)\n",
    "print(\"LR=\",accuracy_LR)\n",
    "print(\"SVC=\",accuracy_SVC)\n",
    "print(\"DTC=\",accuracy_DTC)\n",
    "print(\"GNB=\",accuracy_GNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab8348",
   "metadata": {},
   "source": [
    "Among the models, Logistic Regression and SVM are more accurate. But I felt as SVC takes more running time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
